{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!head SMSSpamCollection.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLclJPnWuxxC",
        "outputId": "79fbf047-e511-468c-b0c4-ec43fb14499c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ham,\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\"\r\n",
            "ham,Ok lar... Joking wif u oni...\r\n",
            "spam,Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\r\n",
            "ham,U dun say so early hor... U c already then say...\r\n",
            "ham,\"Nah I don't think he goes to usf, he lives around here though\"\r\n",
            "spam,\"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\"\r\n",
            "ham,Even my brother is not like to speak with me. They treat me like aids patent.\r\n",
            "ham,As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\r\n",
            "spam,WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\r\n",
            "spam,Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "# The SMSCorpus.csv file is tab-separated and has no header.\n",
        "# The first column is the label (ham or spam) and the second column is the message.\n",
        "# It appears the separator might not be a simple tab, or there are inconsistencies.\n",
        "# Let's try reading with comma separation and then splitting the columns.\n",
        "data = pd.read_csv(\"SMSSpamCollection.csv\", sep=\",\", header=None, names=[\"label_message\"])\n",
        "\n",
        "# Split the combined column into 'label' and 'message'\n",
        "data['label'] = data['label_message'].apply(lambda x: x.split(',', 1)[0])\n",
        "data['message'] = data['label_message'].apply(lambda x: x.split(',', 1)[1] if ',' in x else '')\n",
        "\n",
        "# Drop the original combined column\n",
        "data = data.drop(columns=['label_message'])\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "# Encode labels (ham=0, spam=1)\n",
        "le = LabelEncoder()\n",
        "data[\"label_num\"] = le.fit_transform(data[\"label\"])\n",
        "\n",
        "# Features (text) and target (label)\n",
        "X = data[\"message\"]\n",
        "y = data[\"label_num\"]\n",
        "\n",
        "# Convert text into numerical features (TF-IDF)\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "X_tfidf = vectorizer.fit_transform(X)\n",
        "\n",
        "# Train/test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=2)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "dt = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "dt.fit(x_train, y_train)\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(x_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_dt_pred = dt.predict(x_test)\n",
        "y_lr_pred = lr.predict(x_test)\n",
        "\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "print(\"y_dt_pred shape:\", y_dt_pred.shape)\n",
        "print(\"y_lr_pred shape:\", y_lr_pred.shape)\n",
        "\n",
        "# Accuracy\n",
        "accuracy_dt = accuracy_score(y_test, y_dt_pred)\n",
        "accuracy_lr = accuracy_score(y_test, y_lr_pred)\n",
        "\n",
        "print(\"Decision Tree Accuracy:\", accuracy_dt)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_lr)\n",
        "\n",
        "# Example new prediction\n",
        "sample = [\"Congratulations! You've won a free ticket to Bahamas. Call now!\"]\n",
        "sample_tfidf = vectorizer.transform(sample)\n",
        "print(\"Prediction (0=ham, 1=spam):\", lr.predict(sample_tfidf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXSAs4ubu14V",
        "outputId": "bba91718-451d-4b2e-922c-38a194445f6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  label  \\\n",
            "ham                               Go until jurong point   \n",
            "ham                       Ok lar... Joking wif u oni...   \n",
            "spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
            "ham   U dun say so early hor... U c already then say...   \n",
            "ham                    Nah I don't think he goes to usf   \n",
            "\n",
            "                                                message  \n",
            "ham    crazy.. Available only in bugis n great world...  \n",
            "ham                                                      \n",
            "spam                                                     \n",
            "ham                                                      \n",
            "ham                         he lives around here though  \n",
            "y_test shape: (1115,)\n",
            "y_dt_pred shape: (1115,)\n",
            "y_lr_pred shape: (1115,)\n",
            "Decision Tree Accuracy: 0.03766816143497758\n",
            "Logistic Regression Accuracy: 0.014349775784753363\n",
            "Prediction (0=ham, 1=spam): [3521]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build contingency table\n",
        "table = [[0, 0], [0, 0]]\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    if y_test.iloc[i] == y_lr_pred[i] and y_test.iloc[i] != y_dt_pred[i]:\n",
        "        table[0][1] += 1  # Logistic Regression correct, Decision Tree wrong\n",
        "    elif y_test.iloc[i] != y_lr_pred[i] and y_test.iloc[i] == y_dt_pred[i]:\n",
        "        table[1][0] += 1  # Logistic Regression wrong, Decision Tree correct\n",
        "    elif y_test.iloc[i] == y_lr_pred[i] and y_test.iloc[i] == y_dt_pred[i]:\n",
        "        table[0][0] += 1  # Both correct\n",
        "    elif y_test.iloc[i] != y_lr_pred[i] and y_test.iloc[i] != y_dt_pred[i]:\n",
        "        table[1][1] += 1  # Both wrong\n",
        "\n",
        "# Print the contingency table\n",
        "print(\"Contingency Table (Logistic Regression vs Decision Tree):\")\n",
        "print(pd.DataFrame(table,\n",
        "                   index=[\"LogReg Correct\", \"LogReg Wrong\"],\n",
        "                   columns=[\"DTree Correct\", \"DTree Wrong\"]))\n",
        "\n",
        "# Perform McNemar's test\n",
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "result = mcnemar(table, exact=True)\n",
        "\n",
        "# Summarize the finding\n",
        "print(\"\\nMcNemar's test statistic:\", result.statistic)\n",
        "print(\"p-value:\", result.pvalue)\n",
        "\n",
        "if result.pvalue < 0.05:\n",
        "    print(\"Significant difference between the models.\")\n",
        "else:\n",
        "    print(\"No significant difference between the models.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPIQs_UpvSUN",
        "outputId": "6ed8f139-8d4b-48e6-c1a4-4ee8e71fe16f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contingency Table (Logistic Regression vs Decision Tree):\n",
            "                DTree Correct  DTree Wrong\n",
            "LogReg Correct             13            3\n",
            "LogReg Wrong               29         1070\n",
            "\n",
            "McNemar's test statistic: 3.0\n",
            "p-value: 2.5560148060321808e-06\n",
            "Significant difference between the models.\n"
          ]
        }
      ]
    }
  ]
}